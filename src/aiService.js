// AIæ¨¡å‹æœåŠ¡å…¼å®¹å±‚ - å¢å¼ºç‰ˆæœ¬
export class AIService {
    constructor(storageManager) {
        this.storageManager = storageManager
        this.requestQueue = []
        this.activeRequests = new Map()
        this.maxConcurrentRequests = 3 // æœ€å¤§å¹¶å‘è¯·æ±‚æ•°

        // æ”¯æŒçš„APIæä¾›å•†é…ç½®
        this.apiProviders = {
            openai: {
                name: 'OpenAI',
                baseUrl: 'https://api.openai.com/v1',
                chatEndpoint: '/chat/completions',
                models: [
                    'gpt-4', 'gpt-4-32k', 'gpt-4-turbo', 'gpt-4-vision-preview',
                    'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-instruct'
                ],
                authHeader: 'Bearer',
                defaultModel: 'gpt-3.5-turbo'
            },
            deepseek: {
                name: 'DeepSeek',
                baseUrl: 'https://api.deepseek.com/v1',
                chatEndpoint: '/chat/completions',
                models: ['deepseek-chat', 'deepseek-coder'],
                authHeader: 'Bearer',
                defaultModel: 'deepseek-chat'
            },
            anthropic: {
                name: 'Anthropic',
                baseUrl: 'https://api.anthropic.com/v1',
                chatEndpoint: '/messages',
                models: ['claude-3-opus-20240229', 'claude-3-sonnet-20240229', 'claude-3-haiku-20240307'],
                authHeader: 'x-api-key',
                defaultModel: 'claude-3-sonnet-20240229'
            },
            azure: {
                name: 'Azure OpenAI',
                baseUrl: 'https://{resource}.openai.azure.com/openai/deployments/{deployment}',
                chatEndpoint: '/chat/completions',
                models: ['gpt-4', 'gpt-35-turbo'],
                authHeader: 'api-key',
                defaultModel: 'gpt-35-turbo'
            },
            google: {
                name: 'Google Gemini',
                baseUrl: 'https://generativelanguage.googleapis.com/v1beta',
                chatEndpoint: '/models/{model}:generateContent',
                models: ['gemini-pro', 'gemini-pro-vision'],
                authHeader: 'x-goog-api-key',
                defaultModel: 'gemini-pro'
            },
            local: {
                name: 'æœ¬åœ°éƒ¨ç½²',
                baseUrl: 'http://localhost:8080/v1',
                chatEndpoint: '/chat/completions',
                models: ['local-model'],
                authHeader: 'Bearer',
                defaultModel: 'local-model'
            }
        }
    }

    // å‘é€æ¶ˆæ¯åˆ°AIæ¨¡å‹ - æ”¯æŒå¹¶å‘è¯·æ±‚
    async sendMessage(agent, message, conversationHistory = [], onProgress = null) {
        const requestId = this.generateRequestId()

        return new Promise((resolve, reject) => {
            const request = {
                id: requestId,
                agent,
                message,
                conversationHistory,
                onProgress,
                resolve,
                reject,
                timestamp: Date.now()
            }

            this.requestQueue.push(request)
            this.processQueue()
        })
    }

    // ç”Ÿæˆå”¯ä¸€è¯·æ±‚ID
    generateRequestId() {
        return `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    }

    // å¤„ç†è¯·æ±‚é˜Ÿåˆ—
    async processQueue() {
        // å¦‚æœå·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°æˆ–é˜Ÿåˆ—ä¸ºç©ºï¼Œåˆ™è¿”å›
        if (this.activeRequests.size >= this.maxConcurrentRequests || this.requestQueue.length === 0) {
            return
        }

        // ä»é˜Ÿåˆ—ä¸­å–å‡ºä¸‹ä¸€ä¸ªè¯·æ±‚
        const request = this.requestQueue.shift()
        this.activeRequests.set(request.id, request)

        try {
            const settings = this.storageManager.getSettings()
            const startTime = Date.now()
            let thinkingTime = 0

            let response
            if (settings.apiType === 'network') {
                if (settings.wordByWordOutput && request.onProgress) {
                    // æµå¼è¾“å‡ºæ¨¡å¼
                    response = await this.sendToNetworkAPIStream(request.agent, request.message, request.conversationHistory, settings, request.onProgress)
                    thinkingTime = Date.now() - startTime
                    response = this.addResponseMetadata(response, settings, thinkingTime)
                } else {
                    // æ™®é€šæ¨¡å¼
                    response = await this.sendToNetworkAPI(request.agent, request.message, request.conversationHistory, settings)
                    thinkingTime = Date.now() - startTime
                    response = this.addResponseMetadata(response, settings, thinkingTime)
                }
            } else {
                if (settings.wordByWordOutput && request.onProgress) {
                    // æœ¬åœ°æ¨¡å‹çš„æµå¼è¾“å‡º
                    response = await this.sendToLocalModelStream(request.agent, request.message, request.conversationHistory, settings, request.onProgress)
                    thinkingTime = Date.now() - startTime
                    response = this.addResponseMetadata(response, settings, thinkingTime)
                } else {
                    // æ™®é€šæ¨¡å¼
                    response = await this.sendToLocalModel(request.agent, request.message, request.conversationHistory, settings)
                    thinkingTime = Date.now() - startTime
                    response = this.addResponseMetadata(response, settings, thinkingTime)
                }
            }

            request.resolve(response)
        } catch (error) {
            request.reject(error)
        } finally {
            this.activeRequests.delete(request.id)
            // ç»§ç»­å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯·æ±‚
            this.processQueue()
        }
    }

    // å–æ¶ˆæŒ‡å®šè¯·æ±‚
    cancelRequest(requestId) {
        // ä»é˜Ÿåˆ—ä¸­ç§»é™¤
        const queueIndex = this.requestQueue.findIndex(req => req.id === requestId)
        if (queueIndex !== -1) {
            this.requestQueue.splice(queueIndex, 1)
        }

        // ä»æ´»è·ƒè¯·æ±‚ä¸­ç§»é™¤
        if (this.activeRequests.has(requestId)) {
            this.activeRequests.delete(requestId)
        }
    }

    // è·å–å½“å‰è¯·æ±‚çŠ¶æ€
    getRequestStatus() {
        return {
            queueLength: this.requestQueue.length,
            activeRequests: this.activeRequests.size,
            maxConcurrent: this.maxConcurrentRequests
        }
    }

    // ç½‘ç»œAPIæµå¼è°ƒç”¨
    async sendToNetworkAPIStream(agent, message, conversationHistory, settings, onProgress) {
        const { apiEndpoint, apiKey, modelName, temperature, maxTokens } = settings

        // éªŒè¯åŸºæœ¬é…ç½®
        if (!apiEndpoint) {
            throw new Error('âŒ è¯·é…ç½®APIç«¯ç‚¹')
        }

        if (!apiKey) {
            throw new Error('âŒ è¯·é…ç½®APIå¯†é’¥')
        }

        // æ£€æµ‹APIæä¾›å•†
        const provider = this.detectAPIProvider(apiEndpoint)
        const fullUrl = this.buildRequestUrl(apiEndpoint, provider)

        // æ„å»ºè¯·æ±‚ä½“ï¼Œå¯ç”¨æµå¼è¾“å‡º
        const requestBody = this.buildRequestBody(agent, message, conversationHistory, settings, provider)
        requestBody.stream = true

        console.log(`[AI Service] å‘é€æµå¼ç½‘ç»œAPIè¯·æ±‚:`, {
            provider,
            url: fullUrl,
            model: modelName,
            messageLength: message.length,
            conversationHistoryLength: conversationHistory.length,
            requestBodyMessages: requestBody.messages ? requestBody.messages.length : 'N/A'
        });

        // æ„å»ºè¯·æ±‚å¤´
        const headers = this.buildRequestHeaders(apiKey, provider)

        console.log(`ğŸ” å‘é€æµå¼è¯·æ±‚åˆ°: ${fullUrl}`)

        try {
            const response = await fetch(fullUrl, {
                method: 'POST',
                headers: headers,
                body: JSON.stringify(requestBody)
            })

            if (!response.ok) {
                const errorInfo = await this.parseErrorResponse(response, provider)
                throw new Error(errorInfo)
            }

            // å¤„ç†æµå¼å“åº” - æ·»åŠ å†…å­˜ä¿æŠ¤
            const reader = response.body.getReader()
            const decoder = new TextDecoder()
            let fullResponse = ''
            let buffer = ''
            let chunkCount = 0
            const MAX_RESPONSE_LENGTH = 10000 // é™åˆ¶å“åº”é•¿åº¦
            const MAX_CHUNKS = 1000 // é™åˆ¶æœ€å¤§chunkæ•°é‡

            let lastUpdateTime = 0
            const UPDATE_INTERVAL = 50 // æœ€å°æ›´æ–°é—´éš”(ms)

            while (true) {
                const { done, value } = await reader.read()
                if (done || chunkCount >= MAX_CHUNKS) break

                chunkCount++
                buffer += decoder.decode(value, { stream: true })
                const lines = buffer.split('\n')

                // ä¿ç•™æœ€åä¸€è¡Œï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
                buffer = lines.pop() || ''

                for (const line of lines) {
                    if (line.startsWith('data: ') && line !== 'data: [DONE]') {
                        try {
                            const data = JSON.parse(line.substring(6))
                            const content = this.parseStreamResponseContent(data, provider)
                            if (content && fullResponse.length < MAX_RESPONSE_LENGTH) {
                                fullResponse += content

                                // ä½¿ç”¨èŠ‚æµæ§åˆ¶æ›´æ–°é¢‘ç‡
                                const now = Date.now()
                                if (now - lastUpdateTime >= UPDATE_INTERVAL) {
                                    onProgress(fullResponse)
                                    lastUpdateTime = now
                                }
                            }
                        } catch (e) {
                            // å¿½ç•¥è§£æé”™è¯¯
                        }
                    }
                }
            }

            // ç¡®ä¿æœ€ç»ˆæ–‡æœ¬å®Œæ•´æ˜¾ç¤º
            onProgress(fullResponse)

            return fullResponse

        } catch (error) {
            console.error('ğŸ’¥ ç½‘ç»œAPIæµå¼è°ƒç”¨å¤±è´¥:', error)
            throw error
        }
    }

    // ç½‘ç»œAPIè°ƒç”¨ - å¢å¼ºç‰ˆæœ¬
    async sendToNetworkAPI(agent, message, conversationHistory, settings) {
        const { apiEndpoint, apiKey, modelName, temperature, maxTokens } = settings

        // éªŒè¯åŸºæœ¬é…ç½®
        if (!apiEndpoint) {
            throw new Error('âŒ è¯·é…ç½®APIç«¯ç‚¹')
        }

        if (!apiKey) {
            throw new Error('âŒ è¯·é…ç½®APIå¯†é’¥')
        }

        // éªŒè¯APIç«¯ç‚¹æ ¼å¼
        try {
            new URL(apiEndpoint)
        } catch {
            throw new Error('âŒ APIç«¯ç‚¹æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥æœ‰æ•ˆçš„URL')
        }

        // æ£€æµ‹APIæä¾›å•†
        const provider = this.detectAPIProvider(apiEndpoint)

        // æ„å»ºå®Œæ•´çš„è¯·æ±‚URL
        const fullUrl = this.buildRequestUrl(apiEndpoint, provider)

        // æ„å»ºè¯·æ±‚ä½“
        const requestBody = this.buildRequestBody(agent, message, conversationHistory, settings, provider)
        
        console.log(`[AI Service] å‘é€ç½‘ç»œAPIè¯·æ±‚:`, {
            provider,
            url: fullUrl,
            model: modelName,
            messageLength: message.length,
            conversationHistoryLength: conversationHistory.length,
            requestBodyMessages: requestBody.messages ? requestBody.messages.length : 'N/A'
        });

        // æ„å»ºè¯·æ±‚å¤´
        const headers = this.buildRequestHeaders(apiKey, provider)

        console.log(`ğŸ” å‘é€è¯·æ±‚åˆ°: ${fullUrl}`)

        try {
            const response = await fetch(fullUrl, {
                method: 'POST',                headers: headers,
                body: JSON.stringify(requestBody)
            })

            console.log(`ğŸ“¡ å“åº”çŠ¶æ€: ${response.status} ${response.statusText}`)

            if (!response.ok) {
                const errorInfo = await this.parseErrorResponse(response, provider)
                throw new Error(errorInfo)
            }

            const data = await response.json()
            console.log(`âœ… å“åº”æ•°æ®:`, data)

            // è§£æå“åº”å†…å®¹
            const content = this.parseResponseContent(data, provider)

            if (!content) {
                throw new Error('âŒ æ— æ³•è§£æAPIå“åº”å†…å®¹ï¼Œè¯·æ£€æŸ¥APIé…ç½®å’Œå“åº”æ ¼å¼')
            }

            return content

        } catch (error) {
            console.error('ğŸ’¥ ç½‘ç»œAPIè°ƒç”¨å¤±è´¥:', error)

            // æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            if (error.name === 'TypeError' && error.message.includes('fetch')) {
                throw new Error('ğŸŒ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ï¼š\nâ€¢ APIç«¯ç‚¹æ˜¯å¦æ­£ç¡®\nâ€¢ ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\nâ€¢ æ˜¯å¦é‡åˆ°CORSé™åˆ¶')
            }

            if (error.message.includes('Failed to fetch')) {
                throw new Error('ğŸŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œå¯èƒ½åŸå› ï¼š\nâ€¢ APIç«¯ç‚¹æ— æ³•è®¿é—®\nâ€¢ ç½‘ç»œè¿æ¥é—®é¢˜\nâ€¢ æœåŠ¡å™¨æš‚æ—¶ä¸å¯ç”¨')
            }

            throw error
        }
    }

    // æ£€æµ‹APIæä¾›å•†
    detectAPIProvider(apiEndpoint) {
        const endpoint = apiEndpoint.toLowerCase()

        if (endpoint.includes('openai.com')) {
            return 'openai'
        } else if (endpoint.includes('deepseek.com')) {
            return 'deepseek'
        } else if (endpoint.includes('anthropic.com')) {
            return 'anthropic'
        } else if (endpoint.includes('azure.com') || endpoint.includes('openai.azure.com')) {
            return 'azure'
        } else if (endpoint.includes('googleapis.com') || endpoint.includes('generativelanguage.googleapis.com')) {
            return 'google'
        } else if (endpoint.includes('localhost') || endpoint.includes('127.0.0.1')) {
            return 'local'
        } else {
            return 'custom'
        }
    }

    // æ„å»ºè¯·æ±‚URL
    buildRequestUrl(apiEndpoint, provider) {
        if (provider === 'custom') {
            return apiEndpoint
        }

        const providerConfig = this.apiProviders[provider]
        if (!providerConfig) {
            return apiEndpoint
        }

        // å¦‚æœç”¨æˆ·æä¾›äº†å®Œæ•´çš„ç«¯ç‚¹ï¼Œç›´æ¥ä½¿ç”¨
        if (apiEndpoint.includes(providerConfig.chatEndpoint)) {
            return apiEndpoint
        }

        // å¦åˆ™æ„å»ºå®Œæ•´URL
        return apiEndpoint.endsWith('/')
            ? `${apiEndpoint}${providerConfig.chatEndpoint.substring(1)}`
            : `${apiEndpoint}${providerConfig.chatEndpoint}`
    }

    // æ„å»ºè¯·æ±‚ä½“
    buildRequestBody(agent, message, conversationHistory, settings, provider) {
        const { modelName, temperature, maxTokens } = settings
        const messages = this.buildMessages(agent, message, conversationHistory, settings)

        // ç¡®ä¿æ•°å€¼å‚æ•°ä¸ºæ•°å­—ç±»å‹
        const tempValue = Number(temperature) || 0.7
        const maxTokensValue = Number(maxTokens) || 1000

        // åŸºç¡€è¯·æ±‚ä½“
        let requestBody = {
            model: modelName,
            messages: messages,
            temperature: tempValue,
            max_tokens: maxTokensValue,
            stream: false
        }

        // æä¾›å•†ç‰¹å®šé…ç½®
        switch (provider) {
            case 'anthropic':
                requestBody = {
                    model: modelName,
                    messages: messages,
                    max_tokens: maxTokensValue,
                    temperature: tempValue
                }
                break

            case 'google':
                requestBody = {
                    contents: messages.map(msg => ({
                        parts: [{ text: msg.content }],
                        role: msg.role === 'user' ? 'user' : 'model'
                    }))
                }
                break

            case 'azure':
                // Azureä½¿ç”¨api-versionå‚æ•°
                requestBody.api_version = '2023-12-01-preview'
                break
        }

        return requestBody
    }

    // æ„å»ºè¯·æ±‚å¤´
    buildRequestHeaders(apiKey, provider) {
        const headers = {
            'Content-Type': 'application/json'
        }

        const providerConfig = this.apiProviders[provider]
        if (providerConfig && apiKey) {
            headers[providerConfig.authHeader === 'x-api-key' ? 'x-api-key' : 'Authorization'] =
                providerConfig.authHeader === 'x-api-key' ? apiKey : `${providerConfig.authHeader} ${apiKey}`
        }

        // ç‰¹æ®Šå¤´éƒ¨
        switch (provider) {
            case 'anthropic':
                headers['anthropic-version'] = '2023-06-01'
                break
        }

        return headers
    }

    // è§£æé”™è¯¯å“åº”
    async parseErrorResponse(response, provider) {
        let errorMessage = `âŒ APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`

        try {
            const errorData = await response.json()
            console.log('ğŸ” é”™è¯¯å“åº”æ•°æ®:', errorData)

            if (errorData.error && errorData.error.message) {
                errorMessage = `âŒ ${errorData.error.message}`
            } else if (errorData.message) {
                errorMessage = `âŒ ${errorData.message}`
            } else if (errorData.detail) {
                errorMessage = `âŒ ${errorData.detail}`
            }

            // å¸¸è§é”™è¯¯ä»£ç å¤„ç†
            if (response.status === 401) {
                errorMessage += '\nğŸ”‘ è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®'
            } else if (response.status === 403) {
                errorMessage += '\nğŸš« æƒé™ä¸è¶³ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥æƒé™'
            } else if (response.status === 404) {
                errorMessage += '\nğŸ” èµ„æºæœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥APIç«¯ç‚¹æ˜¯å¦æ­£ç¡®'
            } else if (response.status === 429) {
                errorMessage += '\nâ° è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•'
            } else if (response.status >= 500) {
                errorMessage += '\nğŸ”§ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•'
            }

        } catch {
            // å¦‚æœæ— æ³•è§£æé”™è¯¯å“åº”ï¼Œä½¿ç”¨é»˜è®¤é”™è¯¯ä¿¡æ¯
            console.warn('âš ï¸ æ— æ³•è§£æé”™è¯¯å“åº”')
        }

        return errorMessage
    }

    // è§£ææµå¼å“åº”å†…å®¹
    parseStreamResponseContent(data, provider) {
        // å…¼å®¹ä¸åŒAPIæä¾›å•†çš„æµå¼å“åº”æ ¼å¼
        switch (provider) {
            case 'openai':
            case 'deepseek':
            case 'azure':
            case 'local':
                if (data.choices && data.choices[0] && data.choices[0].delta && data.choices[0].delta.content) {
                    return data.choices[0].delta.content
                }
                break

            case 'anthropic':
                if (data.type === 'content_block_delta' && data.delta && data.delta.text) {
                    return data.delta.text
                }
                break

            case 'google':
                if (data.candidates && data.candidates[0] && data.candidates[0].content) {
                    return data.candidates[0].content.parts[0].text
                }
                break

            case 'custom':
                // å°è¯•å¤šç§å¸¸è§æ ¼å¼
                if (data.choices?.[0]?.delta?.content) {
                    return data.choices[0].delta.content
                } else if (data.delta?.content) {
                    return data.delta.content
                } else if (data.content) {
                    return data.content
                }
                break
        }

        return null
    }

    // è§£æå“åº”å†…å®¹
    parseResponseContent(data, provider) {
        console.log('ğŸ” è§£æå“åº”æ•°æ®:', data)

        // å…¼å®¹ä¸åŒAPIæä¾›å•†çš„å“åº”æ ¼å¼
        switch (provider) {
            case 'openai':
            case 'deepseek':
            case 'azure':
            case 'local':
                if (data.choices && data.choices[0] && data.choices[0].message) {
                    return data.choices[0].message.content
                }
                break

            case 'anthropic':
                if (data.content && data.content[0] && data.content[0].text) {
                    return data.content[0].text
                }
                break

            case 'google':
                if (data.candidates && data.candidates[0] && data.candidates[0].content) {
                    return data.candidates[0].content.parts[0].text
                }
                break

            case 'custom':
                // å°è¯•å¤šç§å¸¸è§æ ¼å¼
                if (data.choices?.[0]?.message?.content) {
                    return data.choices[0].message.content
                } else if (data.content) {
                    return data.content
                } else if (data.result) {
                    return data.result
                } else if (data.text) {
                    return data.text
                }
                break
        }

        console.warn('âš ï¸ æœªçŸ¥çš„APIå“åº”æ ¼å¼:', data)
        return null
    }

    // è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    getSupportedModels(apiEndpoint) {
        const provider = this.detectAPIProvider(apiEndpoint)
        const providerConfig = this.apiProviders[provider]

        if (providerConfig) {
            return providerConfig.models
        }

        // å¯¹äºè‡ªå®šä¹‰ç«¯ç‚¹ï¼Œè¿”å›é€šç”¨æ¨¡å‹åˆ—è¡¨
        return [
            'gpt-4', 'gpt-4-turbo', 'gpt-3.5-turbo',
            'deepseek-chat', 'deepseek-coder',
            'claude-3-opus', 'claude-3-sonnet', 'claude-3-haiku',
            'gemini-pro', 'custom-model'
        ]
    }

    // è·å–APIæä¾›å•†ä¿¡æ¯
    getAPIProviderInfo(apiEndpoint) {
        const provider = this.detectAPIProvider(apiEndpoint)
        return this.apiProviders[provider] || {
            name: 'è‡ªå®šä¹‰API',
            models: ['custom-model']
        }
    }

    // æœ¬åœ°æ¨¡å‹æµå¼è°ƒç”¨ - ä¼˜åŒ–ç‰ˆæœ¬
    async sendToLocalModelStream(agent, message, conversationHistory, settings, onProgress) {
        const messages = this.buildMessages(agent, message, conversationHistory, settings)

        console.log(`[AI Service] å‘é€æµå¼æœ¬åœ°æ¨¡å‹è¯·æ±‚:`, {
            model: 'local-model',
            messageLength: message.length,
            conversationHistoryLength: conversationHistory.length,
            messagesUsed: messages.length
        });

        // åŸºäºæ™ºèƒ½ä½“é…ç½®ç”Ÿæˆå›å¤
        const context = agent.prompt || ''
        const scenario = agent.scenario || ''
        const keyPoints = agent.keyPoints || ''

        let fullResponse = ''

        if (context.includes('åŠ©æ‰‹') || context.includes('assistant')) {
            fullResponse = this.generateHelpfulResponse(message, context)
        } else if (context.includes('æœ‹å‹') || context.includes('friend')) {
            fullResponse = this.generateFriendlyResponse(message, context)
        } else if (context.includes('ä¸“å®¶') || context.includes('expert')) {
            fullResponse = this.generateExpertResponse(message, context)
        } else {
            fullResponse = this.generateDefaultResponse(message, context)
        }

        // æ·»åŠ åœºæ™¯å’Œè¦ç‚¹ä¿¡æ¯
        if (scenario) {
            fullResponse = `[åœºæ™¯: ${scenario}] ${fullResponse}`
        }

        if (keyPoints) {
            fullResponse += `\n\n[è¦ç‚¹æé†’: ${keyPoints}]`
        }

        // ä¼˜åŒ–çš„æµå¼è¾“å‡º - ä½¿ç”¨å­—ç¬¦çº§è¾“å‡ºï¼Œä½†å‡å°‘æ›´æ–°é¢‘ç‡
        let currentText = ''
        const chars = fullResponse.split('')
        let lastUpdateTime = 0
        const UPDATE_INTERVAL = 50 // æœ€å°æ›´æ–°é—´éš”(ms)

        for (let i = 0; i < chars.length; i++) {
            currentText += chars[i]

            // ä½¿ç”¨èŠ‚æµæ§åˆ¶æ›´æ–°é¢‘ç‡
            const now = Date.now()
            if (now - lastUpdateTime >= UPDATE_INTERVAL) {
                onProgress(currentText)
                lastUpdateTime = now
            }

            // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿï¼Œä½†ä½¿ç”¨æ›´åˆç†çš„å»¶è¿Ÿæ—¶é—´
            await new Promise(resolve => setTimeout(resolve, 30 + Math.random() * 30))
        }

        // ç¡®ä¿æœ€ç»ˆæ–‡æœ¬å®Œæ•´æ˜¾ç¤º
        if (currentText !== fullResponse) {
            onProgress(fullResponse)
        }

        return fullResponse
    }

    // æœ¬åœ°æ¨¡å‹è°ƒç”¨ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰
    async sendToLocalModel(agent, message, conversationHistory, settings) {
        const messages = this.buildMessages(agent, message, conversationHistory, settings)
        
        console.log(`[AI Service] å‘é€æœ¬åœ°æ¨¡å‹è¯·æ±‚:`, {
            model: 'local-model',
            messageLength: message.length,
            conversationHistoryLength: conversationHistory.length,
            messagesUsed: messages.length
        });

        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 1000))

        // åŸºäºæ™ºèƒ½ä½“é…ç½®ç”Ÿæˆå›å¤
        const context = agent.prompt || ''
        const scenario = agent.scenario || ''
        const keyPoints = agent.keyPoints || ''

        let response = ''

        if (context.includes('åŠ©æ‰‹') || context.includes('assistant')) {
            response = this.generateHelpfulResponse(message, context)
        } else if (context.includes('æœ‹å‹') || context.includes('friend')) {
            response = this.generateFriendlyResponse(message, context)
        } else if (context.includes('ä¸“å®¶') || context.includes('expert')) {
            response = this.generateExpertResponse(message, context)
        } else {
            response = this.generateDefaultResponse(message, context)
        }

        // æ·»åŠ åœºæ™¯å’Œè¦ç‚¹ä¿¡æ¯
        if (scenario) {
            response = `[åœºæ™¯: ${scenario}] ${response}`
        }

        if (keyPoints) {
            response += `\n\n[è¦ç‚¹æé†’: ${keyPoints}]`
        }

        return response
    }

    // æ„å»ºæ¶ˆæ¯æ•°ç»„
    buildMessages(agent, currentMessage, conversationHistory, settings = null) {
        // è·å–ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼Œå¦‚æœæ²¡æœ‰æä¾›settingsåˆ™ä½¿ç”¨é»˜è®¤å€¼50
        const maxHistoryLength = settings && settings.contextLength ? settings.contextLength : 50
        
        // é™åˆ¶å¯¹è¯å†å²é•¿åº¦ï¼Œåªå–æœ€è¿‘çš„æ¶ˆæ¯
        const recentHistory = conversationHistory.slice(-maxHistoryLength)

        // è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºæˆªæ–­å‰åçš„å†å²æ¶ˆæ¯æ•°é‡
        if (conversationHistory.length > maxHistoryLength) {
            console.log(`[AI Service] æ¶ˆæ¯å†å²å·²æˆªæ–­: ${conversationHistory.length} -> ${recentHistory.length} æ¡æ¶ˆæ¯ (é™åˆ¶: ${maxHistoryLength})`);
        } else {
            console.log(`[AI Service] æ¶ˆæ¯å†å²æœªæˆªæ–­: ${conversationHistory.length} æ¡æ¶ˆæ¯ (é™åˆ¶: ${maxHistoryLength})`);
        }

        const messages = []

        // ç³»ç»Ÿæç¤ºè¯
        if (agent.prompt) {
            messages.push({
                role: 'system',
                content: agent.prompt
            })
        }

        // å¯¹è¯å†å²
        recentHistory.forEach(msg => {
            messages.push({
                role: msg.role,
                content: msg.content
            })
        })

        // å½“å‰æ¶ˆæ¯
        messages.push({
            role: 'user',
            content: currentMessage
        })

        // è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºæ„å»ºçš„æ€»æ¶ˆæ¯æ•°é‡
        console.log(`[AI Service] æ„å»ºçš„æ¶ˆæ¯æ€»æ•°: ${messages.length} (ç³»ç»Ÿæ¶ˆæ¯: ${agent.prompt ? 1 : 0}, å†å²æ¶ˆæ¯: ${recentHistory.length}, å½“å‰æ¶ˆæ¯: 1)`);
        
        return messages
    }

    // æ¨¡æ‹Ÿå›å¤ç”Ÿæˆå‡½æ•°
    generateHelpfulResponse(message, context) {
        const responses = [
            `æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ã€‚${message} è¿™ä¸ªé—®é¢˜å¯ä»¥ä»å¤šä¸ªè§’åº¦æ¥åˆ†æã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘...`,
            `æ„Ÿè°¢æ‚¨çš„æé—®ã€‚å…³äº"${message}"ï¼Œæˆ‘çš„å»ºè®®æ˜¯...`,
            `è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚è®©æˆ‘ä¸ºæ‚¨è¯¦ç»†è§£é‡Šä¸€ä¸‹${message}çš„ç›¸å…³å†…å®¹...`,
            `æˆ‘æ³¨æ„åˆ°æ‚¨æåˆ°${message}ã€‚æ ¹æ®æˆ‘çš„çŸ¥è¯†ï¼Œè¿™é‡Œæœ‰å‡ ä¸ªè¦ç‚¹éœ€è¦å…³æ³¨...`
        ]
        return responses[Math.floor(Math.random() * responses.length)]
    }

    generateFriendlyResponse(message, context) {
        const responses = [
            `å“ˆå“ˆï¼Œ${message} è¿™ä¸ªè¯é¢˜å¾ˆæœ‰æ„æ€ï¼æˆ‘è§‰å¾—...`,
            `æœ‹å‹ï¼Œå…³äº${message}ï¼Œæˆ‘çš„çœ‹æ³•æ˜¯...`,
            `å“‡ï¼Œ${message} è¿™ä¸ªè¯é¢˜æˆ‘ä»¬å¾—å¥½å¥½èŠèŠï¼`,
            `å˜¿ï¼Œ${message} è¿™ä¸ªé—®é¢˜é—®å¾—å¥½ï¼è®©æˆ‘æƒ³æƒ³...`
        ]
        return responses[Math.floor(Math.random() * responses.length)]
    }

    generateExpertResponse(message, context) {
        const responses = [
            `ä»ä¸“ä¸šè§’åº¦æ¥çœ‹ï¼Œ${message} æ¶‰åŠä»¥ä¸‹å‡ ä¸ªå…³é”®å› ç´ ...`,
            `æ ¹æ®è¡Œä¸šæ ‡å‡†ï¼Œ${message} çš„æœ€ä½³å®è·µæ˜¯...`,
            `åœ¨ä¸“ä¸šé¢†åŸŸå†…ï¼Œ${message} é€šå¸¸éµå¾ªè¿™æ ·çš„åŸåˆ™...`,
            `ä½œä¸ºä¸“å®¶ï¼Œæˆ‘è®¤ä¸º${message} çš„æ ¸å¿ƒé—®é¢˜åœ¨äº...`
        ]
        return responses[Math.floor(Math.random() * responses.length)]
    }

    generateDefaultResponse(message, context) {
        const responses = [
            `æˆ‘æ”¶åˆ°äº†æ‚¨çš„æ¶ˆæ¯ï¼š${message}ã€‚è®©æˆ‘æ€è€ƒä¸€ä¸‹å¦‚ä½•å›å¤...`,
            `å…³äº"${message}"ï¼Œæˆ‘çš„æƒ³æ³•æ˜¯...`,
            `æ„Ÿè°¢æ‚¨çš„æ¶ˆæ¯ã€‚${message} è¿™ä¸ªè¯é¢˜å€¼å¾—æ¢è®¨...`,
            `æˆ‘ç†è§£æ‚¨è¯´çš„æ˜¯${message}ã€‚ä»æˆ‘çš„è§’åº¦æ¥çœ‹...`
        ]
        return responses[Math.floor(Math.random() * responses.length)]
    }

    // æµå¼å“åº”ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
    async *sendMessageStream(agent, message, conversationHistory = []) {
        const fullResponse = await this.sendMessage(agent, message, conversationHistory)

        // æ¨¡æ‹Ÿæµå¼è¾“å‡º
        const words = fullResponse.split(' ')
        for (let i = 0; i < words.length; i++) {
            await new Promise(resolve => setTimeout(resolve, 50 + Math.random() * 100))
            yield words.slice(0, i + 1).join(' ')
        }
    }

    // é€å­—è¾“å‡º - ä¼˜åŒ–ç‰ˆæœ¬
    async outputWordByWord(response, onProgress, settings, thinkingTime) {
        let currentText = ''
        const chars = response.split('')
        let lastUpdateTime = 0
        const UPDATE_INTERVAL = 50 // æœ€å°æ›´æ–°é—´éš”(ms)
        let animationFrameId = null

        for (let i = 0; i < chars.length; i++) {
            currentText += chars[i]

            // ä½¿ç”¨èŠ‚æµæ§åˆ¶æ›´æ–°é¢‘ç‡
            const now = Date.now()
            if (now - lastUpdateTime >= UPDATE_INTERVAL) {
                // ä½¿ç”¨ requestAnimationFrame è¿›è¡Œæ‰¹é‡æ›´æ–°
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId)
                }

                animationFrameId = requestAnimationFrame(() => {
                    if (onProgress) {
                        const progressText = this.addResponseMetadata(currentText, settings, thinkingTime, true)
                        onProgress(progressText)
                    }
                })

                lastUpdateTime = now
            }

            // æ¨¡æ‹Ÿæ‰“å­—é€Ÿåº¦
            await new Promise(resolve => setTimeout(resolve, 30 + Math.random() * 30))
        }

        // ç¡®ä¿æœ€ç»ˆæ–‡æœ¬å®Œæ•´æ˜¾ç¤º
        if (currentText !== response) {
            requestAnimationFrame(() => {
                if (onProgress) {
                    const progressText = this.addResponseMetadata(response, settings, thinkingTime, true)
                    onProgress(progressText)
                }
            })
        }

        return this.addResponseMetadata(response, settings, thinkingTime)
    }

    // æ·»åŠ å“åº”å…ƒæ•°æ®
    addResponseMetadata(response, settings, thinkingTime, isPartial = false) {
        // è®¡ç®—ä»¤ç‰Œæ•°ï¼ˆç®€å•ä¼°ç®—ï¼š1ä¸ªæ±‰å­—â‰ˆ2ä¸ªtokenï¼Œ1ä¸ªè‹±æ–‡å•è¯â‰ˆ1.3ä¸ªtokenï¼‰
        const chineseChars = (response.match(/[\u4e00-\u9fa5]/g) || []).length
        const englishWords = (response.match(/\b[a-zA-Z]+\b/g) || []).length
        const otherChars = response.length - chineseChars - englishWords
        const estimatedTokens = Math.round(chineseChars * 2 + englishWords * 1.3 + otherChars * 0.5)

        // åˆ›å»ºå…ƒæ•°æ®å¯¹è±¡
        const metadata = {
            response: response,
            tokens: settings.showTokens && !isPartial ? estimatedTokens : null,
            thinkingTime: settings.showThinkingTime && !isPartial ? thinkingTime : null
        }

        return metadata
    }

    // æ ¼å¼åŒ–æ€è€ƒæ—¶é—´
    formatThinkingTime(milliseconds) {
        if (milliseconds < 1000) {
            return `${milliseconds}ms`
        } else if (milliseconds < 60000) {
            return `${(milliseconds / 1000).toFixed(1)}s`
        } else {
            const minutes = Math.floor(milliseconds / 60000)
            const seconds = Math.floor((milliseconds % 60000) / 1000)
            return `${minutes}m ${seconds}s`
        }
    }

    // ç”Ÿæˆæ¨èå›å¤ - æ”¯æŒå¹¶å‘è¯·æ±‚
    async generateSuggestedReplies(agent, conversationHistory, settings) {
        const requestId = this.generateRequestId()

        return new Promise((resolve, reject) => {
            const request = {
                id: requestId,
                agent,
                conversationHistory,
                settings,
                resolve,
                reject,
                timestamp: Date.now(),
                type: 'suggestions'
            }

            this.requestQueue.push(request)
            this.processSuggestionQueue()
        })
    }

    // å¤„ç†æ¨èå›å¤è¯·æ±‚é˜Ÿåˆ—
    async processSuggestionQueue() {
        // å¦‚æœå·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°æˆ–é˜Ÿåˆ—ä¸ºç©ºï¼Œåˆ™è¿”å›
        if (this.activeRequests.size >= this.maxConcurrentRequests || this.requestQueue.length === 0) {
            return
        }

        // ä»é˜Ÿåˆ—ä¸­å–å‡ºä¸‹ä¸€ä¸ªæ¨èå›å¤è¯·æ±‚
        const suggestionRequest = this.requestQueue.find(req => req.type === 'suggestions')
        if (!suggestionRequest) {
            return
        }

        // ä»é˜Ÿåˆ—ä¸­ç§»é™¤è¯¥è¯·æ±‚
        const queueIndex = this.requestQueue.indexOf(suggestionRequest)
        this.requestQueue.splice(queueIndex, 1)
        this.activeRequests.set(suggestionRequest.id, suggestionRequest)

        try {
            // æ„å»ºæ¨èå›å¤çš„æç¤ºè¯
            const suggestionPrompt = this.buildSuggestionPrompt(suggestionRequest.agent, suggestionRequest.conversationHistory)

            let suggestions
            if (suggestionRequest.settings.apiType === 'network') {
                suggestions = await this.generateNetworkSuggestions(suggestionPrompt, suggestionRequest.settings)
            } else {
                suggestions = await this.generateLocalSuggestions(suggestionPrompt, suggestionRequest.agent)
            }

            suggestionRequest.resolve(suggestions)
        } catch (error) {
            suggestionRequest.reject(error)
        } finally {
            this.activeRequests.delete(suggestionRequest.id)
            // ç»§ç»­å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯·æ±‚
            this.processSuggestionQueue()
        }
    }

    // æ„å»ºæ¨èå›å¤æç¤ºè¯
    buildSuggestionPrompt(agent, conversationHistory) {
        const lastUserMessage = conversationHistory
            .filter(msg => msg.role === 'assistant')
            .pop()

        const lastMessage = lastUserMessage ? lastUserMessage.content : 'å¼€å§‹å¯¹è¯'
        const agentContext = agent.prompt || ''
        const agentScenario = agent.scenario || ''

        return `è¯·åŸºäºä»¥ä¸‹å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆ4ä¸ªä¸åŒçš„æ¨èå›å¤é€‰é¡¹ã€‚

å¯¹è¯ä¸Šä¸‹æ–‡ï¼š
- æ™ºèƒ½ä½“è§’è‰²ï¼š${agentContext}
- æ™ºèƒ½ä½“æœ€åæ¶ˆæ¯ï¼š"${lastMessage}"

è¦æ±‚ï¼š
1. ç”Ÿæˆ4ä¸ªä¸åŒçš„å›å¤é€‰é¡¹ï¼Œä»ç”¨æˆ·çš„è§†è§’å‡ºå‘
2. æ¯ä¸ªå›å¤åº”è¯¥ç®€æ´æ˜äº†ï¼Œé€‚åˆä½œä¸ºå¿«é€Ÿå›å¤
3. å›å¤åº”è¯¥ç¬¦åˆæ™ºèƒ½ä½“çš„è§’è‰²è®¾å®šï¼Œä½†è¦ä»¥ç”¨æˆ·çš„å£å»è¡¨è¾¾
4. å›å¤åº”è¯¥ä¸å¯¹è¯ä¸Šä¸‹æ–‡ç›¸å…³
5. ä½¿ç”¨ä¸­æ–‡å›å¤
6. ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è¯´æ˜æˆ–æ ¼å¼

è¯·ç›´æ¥è¿”å›4ä¸ªå›å¤é€‰é¡¹ï¼Œæ¯ä¸ªé€‰é¡¹ç”¨æ¢è¡Œåˆ†éš”ï¼Œä¸è¦ä½¿ç”¨æ•°å­—æˆ–é¡¹ç›®ç¬¦å·ã€‚`
    }

    // ç½‘ç»œAPIç”Ÿæˆæ¨èå›å¤
    async generateNetworkSuggestions(suggestionPrompt, settings) {
        const { apiEndpoint, apiKey, modelName } = settings

        if (!apiEndpoint || !apiKey) {
            throw new Error('è¯·é…ç½®APIç«¯ç‚¹å’Œå¯†é’¥')
        }

        const provider = this.detectAPIProvider(apiEndpoint)
        const fullUrl = this.buildRequestUrl(apiEndpoint, provider)
        const headers = this.buildRequestHeaders(apiKey, provider)

        const requestBody = {
            model: modelName,
            messages: [
                {
                    role: 'user',
                    content: suggestionPrompt
                }
            ],
            temperature: 0.8, // ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—å¤šæ ·æ€§
            max_tokens: 200
        }

        try {
            const response = await fetch(fullUrl, {
                method: 'POST',
                headers: headers,
                body: JSON.stringify(requestBody)
            })

            if (!response.ok) {
                throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status}`)
            }

            const data = await response.json()
            const content = this.parseResponseContent(data, provider)

            if (!content) {
                throw new Error('æ— æ³•è§£ææ¨èå›å¤')
            }

            return this.parseSuggestedReplies(content)
        } catch (error) {
            console.error('ç”Ÿæˆæ¨èå›å¤å¤±è´¥:', error)
            throw error
        }
    }

    // æœ¬åœ°æ¨¡å‹ç”Ÿæˆæ¨èå›å¤
    async generateLocalSuggestions(suggestionPrompt, agent) {
        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await new Promise(resolve => setTimeout(resolve, 500 + Math.random() * 500))

        const context = agent.prompt || ''
        const scenario = agent.scenario || ''

        // åŸºäºæ™ºèƒ½ä½“ç±»å‹ç”Ÿæˆä¸åŒçš„æ¨èå›å¤ - ä»ç”¨æˆ·è§†è§’å‡ºå‘
        let suggestions = []

        if (context.includes('åŠ©æ‰‹') || context.includes('assistant')) {
            suggestions = [
                'è¯·å¸®æˆ‘è¯¦ç»†è§£é‡Šä¸€ä¸‹è¿™ä¸ªé—®é¢˜',
                'æˆ‘æƒ³äº†è§£ä¸€äº›å®ç”¨çš„å»ºè®®',
                'è¿™ä¸ªé—®é¢˜å¯ä»¥ä»å“ªäº›è§’åº¦åˆ†æï¼Ÿ',
                'æˆ‘éœ€è¦æ›´å¤šçš„ä¿¡æ¯æ¥ç†è§£è¿™ä¸ªé—®é¢˜'
            ]
        } else if (context.includes('æœ‹å‹') || context.includes('friend')) {
            suggestions = [
                'å“ˆå“ˆï¼Œè¿™ä¸ªè¯é¢˜çœŸæœ‰æ„æ€ï¼',
                'æœ‹å‹ï¼Œæˆ‘ä¹Ÿæœ‰ç±»ä¼¼çš„æƒ³æ³•',
                'å“‡ï¼Œæˆ‘ä»¬ç»§ç»­èŠè¿™ä¸ªè¯é¢˜å§ï¼',
                'å˜¿ï¼Œè¿™ä¸ªé—®é¢˜æˆ‘ä¹Ÿå¾ˆå¥½å¥‡'
            ]
        } else if (context.includes('ä¸“å®¶') || context.includes('expert')) {
            suggestions = [
                'æˆ‘æƒ³äº†è§£è¿™ä¸ªé—®é¢˜çš„ä¸“ä¸šè§‚ç‚¹',
                'è¯·é—®è¿™ä¸ªé¢†åŸŸçš„æœ€ä½³å®è·µæ˜¯ä»€ä¹ˆï¼Ÿ',
                'ä»ä¸“ä¸šè§’åº¦åº”è¯¥æ€ä¹ˆçœ‹å¾…è¿™ä¸ªé—®é¢˜ï¼Ÿ',
                'æˆ‘æƒ³çŸ¥é“è¿™ä¸ªé—®é¢˜çš„æ ¸å¿ƒè¦ç‚¹'
            ]
        } else {
            suggestions = [
                'æˆ‘æ˜ç™½äº†ï¼Œè®©æˆ‘æƒ³æƒ³',
                'è°¢è°¢åˆ†äº«ï¼Œæˆ‘çš„æƒ³æ³•æ˜¯...',
                'è¿™ä¸ªè¯é¢˜å¾ˆæœ‰æ„æ€ï¼Œç»§ç»­è¯´å§',
                'æˆ‘æ”¶åˆ°äº†ï¼Œè®©æˆ‘å›å¤ä¸€ä¸‹'
            ]
        }

        // æ·»åŠ åœºæ™¯ç›¸å…³çš„å›å¤
        if (scenario) {
            suggestions = suggestions.map(suggestion =>
                `${suggestion} [${scenario}]`
            )
        }

        return suggestions
    }

    // è§£ææ¨èå›å¤
    parseSuggestedReplies(content) {
        // æŒ‰æ¢è¡Œåˆ†å‰²å¹¶æ¸…ç†
        const replies = content
            .split('\n')
            .map(reply => reply.trim())
            .filter(reply => reply.length > 0 && !reply.startsWith('å›å¤') && !reply.match(/^\d+\./))

        // å¦‚æœè§£æå‡ºçš„å›å¤å°‘äº4ä¸ªï¼Œä½¿ç”¨é»˜è®¤å›å¤ - ä»ç”¨æˆ·è§†è§’å‡ºå‘
        if (replies.length < 4) {
            const defaultReplies = [
                'æˆ‘æ˜ç™½äº†',
                'è°¢è°¢åˆ†äº«',
                'è¿™ä¸ªè¯é¢˜å¾ˆæœ‰æ„æ€',
                'è®©æˆ‘æƒ³æƒ³'
            ]
            return defaultReplies.slice(0, 4)
        }

        return replies.slice(0, 4)
    }
}